{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Audio Video Search with Meta AI ImageBind\n",
    "This recipe demonstrates how build multi-modal search (image, audio, video) `Meta AI ImageBind` model ([multi2vec-bind](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-bind)).\n",
    "\n",
    "ImageBind allows us to search through text, image, audio and video.\n",
    "\n",
    "This recipe will focus on searching through image, audio, video (skipping searching through text):\n",
    "* [text-to-media search](#text-to-media-search) - provide text as input to search through media\n",
    "* [image-to-media search](#image-to-media-search) - provide **image** as input to search through media\n",
    "* [audio-to-media search](#audio-to-media-search) - provide **audio** as input to search through media\n",
    "* [video-to-media search](#video-to-media-search) - provide **video** as input to search through media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaviate Setup\n",
    "\n",
    "The ImageBind model is only available with local Weaviate deployments with Docker or Kubernetes.\n",
    "\n",
    "ImageBind is not supported with Weaviate Cloud Services (WCS).\n",
    "\n",
    "### Steps to deploy Weaviate locally with ImageBind\n",
    "\n",
    "1. Get a docker compose file.\n",
    "    \n",
    "    Run the following command in your terminal:\n",
    "\n",
    "    ```\n",
    "    curl -o docker-compose.yml \"https://configuration.weaviate.io/v2/docker-compose/docker-compose.yml?bind_model=imagebind&generative_cohere=false&generative_openai=false&generative_palm=false&media_type=bind&modules=modules&ref2vec_centroid=false&reranker_cohere=false&reranker_transformers=false&runtime=docker-compose&weaviate_version=v1.21.8&weaviate_volume=named-volume\"\n",
    "    ```\n",
    "\n",
    "    This will download `docker-compose.yml` file for you.\n",
    "\n",
    "2. Run Weaviate+Bind with Docker Compose\n",
    "\n",
    "    > If you are new to `Docker Compose`, [here are instructions on how to install it](https://docs.docker.com/compose/install/).\n",
    "\n",
    "    To start the docker image defined in the `docker-compose.yml` file, call:\n",
    "\n",
    "    ```\n",
    "    docker compose up\n",
    "    ```\n",
    "    \n",
    "    > Note #1 - the first time you run the command, Docker will download a ~6GB image.\n",
    "    \n",
    "    > Note #2 â€“ to shut down a running docker image, press CMD+C or CTRL+C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "\n",
    "# Connect to Weaviate\n",
    "client = weaviate.Client(\n",
    "  url=\"http://localhost:8080\",  # URL to your local Weaviate instance\n",
    ")\n",
    "\n",
    "client.is_ready() # Test the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `Animals` collection\n",
    "\n",
    "The collection has the following key characteristics:\n",
    "1. Name: `\"Animals\"`\n",
    "2. Vectorizer: `multi2vec-clip`\n",
    "3. Image property: `\"img\"` - Weaviate will use values in \"img\" property to generate vectors. Note, you can call it anything you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the collection if it exists.\n",
    "# Note you should skip this step if you don't want to reimport the data every time.\n",
    "if client.schema.exists(\"Craigslist\"):\n",
    "    client.schema.delete_class(\"Craigslist\")\n",
    "\n",
    "craigslist = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"Craigslist\",\n",
    "            \n",
    "            \"vectorizer\": \"multi2vec-bind\",\n",
    "            \n",
    "            \"moduleConfig\": {\n",
    "                \"multi2vec-bind\": {\n",
    "                    \"textFields\": [\"name\", \"desc\", \"url\"],\n",
    "                    \"imageFields\": [\"image\"],\n",
    "                    \"audioFields\": [\"audio\"],\n",
    "                    \"videoFields\": [\"video\"],\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "client.schema.create(craigslist)\n",
    "print(\"Successfully created Craigslist collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to delete a specific resource\n",
    "> Only use, if you need to delete a specific type of resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batch.delete_objects(\n",
    "    class_name='Craigslist',\n",
    "    where={\n",
    "        'path': ['mediaType'],\n",
    "        'operator': 'Equal',\n",
    "        # 'valueText': 'image'\n",
    "        # 'valueText': 'audio'\n",
    "        'valueText': 'video'\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Media\n",
    "For every object, we will store:\n",
    "* `name` - the file name \n",
    "* `path` - path to the file, so that we could display returned images at query time.\n",
    "* (one of the following) media:\n",
    "    * `image` - a base64 representation of the image file, Weaviate will use it to generate a vector - see `imageFields`.\n",
    "    * `audio` - a base64 representation of the audio file, Weaviate will use it to generate a vector - see `audioFields`.\n",
    "    * `video` - a base64 representation of the video file, Weaviate will use it to generate a vector - see `videoFields`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import base64\n",
    "\n",
    "# Helper function to convert a file to base64 representation\n",
    "def toBase64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of source images \n",
    "# source = [\"cat1.jpg\", \"cat2.jpg\", \"cat3.jpg\",\n",
    "#           \"dog1.jpg\", \"dog2.jpg\", \"dog3.jpg\",\n",
    "#           \"meerkat1.jpg\", \"meerkat2.jpg\", \"meerkat3.jpg\"]\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the directory path\n",
    "image_directory = \"./source/image/\"\n",
    "\n",
    "# List all files in the specified directory\n",
    "file_list = os.listdir(image_directory)\n",
    "\n",
    "# Filter only the image files with a specific extension, e.g., \".jpg\"\n",
    "image_files = [file for file in file_list if file.endswith(\".jpeg\")]\n",
    "\n",
    "text_prefix = \"./source/text/\"\n",
    "\n",
    "client.batch.configure(batch_size=3)  # Load images in batches of 3\n",
    "with client.batch as batch:\n",
    "\n",
    "    for name in image_files:\n",
    "        image_name = os.path.basename(name).split(\".jpeg\")[0]\n",
    "        print(f\"Adding {name}\")\n",
    "\n",
    "        # Build the path to the image file\n",
    "        path = image_directory + name\n",
    "\n",
    "        description = \"\"\n",
    "        url = \"\"\n",
    "        try:\n",
    "            fname = os.path.join(text_prefix, image_name + \"-desc.txt\")\n",
    "            print(f\"{fname}\")\n",
    "            with open(os.path.join(text_prefix, image_name + \"-desc.txt\"), \"r\") as file:\n",
    "                description = file.read()\n",
    "            with open(os.path.join(text_prefix, image_name + \"-link.txt\"), \"r\") as file:\n",
    "                url = file.read()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        # Object to store in Weaviate\n",
    "        properties = {\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"desc\": description,\n",
    "            \"url\": url,\n",
    "            \"image\": toBase64(path), # Weaviate will use the base64 representation of the file to generate a vector.\n",
    "            \"mediaType\": \"image\"\n",
    "        }\n",
    "\n",
    "        # Add the object to Weaviate\n",
    "        client.batch.add_data_object(properties, \"Craigslist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of source audio files \n",
    "source = os.listdir('source/audio')\n",
    "\n",
    "client.batch.configure(batch_size=3)  # Load images in batches of 1, as these might be big files\n",
    "with client.batch as batch:\n",
    "\n",
    "    for name in source:\n",
    "        print(f\"Adding {name}\")\n",
    "\n",
    "        # Build the path to the image file\n",
    "        path = \"./source/audio/\" + name\n",
    "\n",
    "        # Object to store in Weaviate\n",
    "        properties = {\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"audio\": toBase64(path), # Weaviate will use the base64 representation of the file to generate a vector.\n",
    "            \"mediaType\": \"audio\"\n",
    "        }\n",
    "\n",
    "        # Add the object to Weaviate\n",
    "        client.batch.add_data_object(properties, \"Animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of source video \n",
    "source = [\n",
    "    \"cat-clean.mp4\", \"cat-play.mp4\",\n",
    "    \"dog-high-five.mp4\", \"dog-with-stick.mp4\",\n",
    "    \"meerkat-dig.mp4\", \"meerkat-watch.mp4\"\n",
    "]\n",
    "\n",
    "client.batch.configure(batch_size=1)  # Load images in batches of 1, as these might be big files\n",
    "with client.batch as batch:\n",
    "\n",
    "    for name in source:\n",
    "        print(f\"Adding {name}\")\n",
    "\n",
    "        # Build the path to the image file\n",
    "        path = \"./source/video/\" + name\n",
    "\n",
    "        # Object to store in Weaviate\n",
    "        properties = {\n",
    "            \"name\": name,\n",
    "            \"path\": path,\n",
    "            \"video\": toBase64(path), # Weaviate will use the base64 representation of the file to generate a vector.\n",
    "            \"mediaType\": \"video\"\n",
    "        }\n",
    "\n",
    "        # Add the object to Weaviate\n",
    "        client.batch.add_data_object(properties, \"Animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of objects in the Animals collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of objects in the Animals collection\n",
    "client.query.aggregate(\"Craigslist\").with_meta_count().do()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to display results\n",
    "import json\n",
    "from IPython.display import Image, Audio, Video\n",
    "\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "def display_media(item):\n",
    "    path = item[\"path\"]\n",
    "\n",
    "    if(item[\"mediaType\"] == \"image\"):\n",
    "        display(Image(path))\n",
    "\n",
    "    elif(item[\"mediaType\"] == \"video\"):\n",
    "        display(Video(path))\n",
    "        \n",
    "    elif(item[\"mediaType\"] == \"audio\"):\n",
    "        display(Audio(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Media search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for media with \"dog with stick\", \"cat playing with mouse\", \"dog high five\", \"puppy\"\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Craigslist\", \"name path desc url mediaType\")\n",
    "    .with_near_text(\n",
    "        #{\"concepts\": \"dog with stick\"}\n",
    "        {\"concepts\": \"tesla model X with red color\"}\n",
    "        # {\"concepts\": \"dog high five\"}\n",
    "        # {\"concepts\": \"puppy\"}\n",
    "    )\n",
    "    .with_limit(10)\n",
    "    .with_additional('distance')\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Craigslist\"]\n",
    "\n",
    "json_print(result)\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for r in result:\n",
    "    if r['_additional']['distance'] < 0.5:\n",
    "        final_results.append(r)\n",
    "\n",
    "if final_results:\n",
    "    # Display the first result\n",
    "    display_media(final_results[0])\n",
    "else:\n",
    "    print(f\"No results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to Media search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('test/test-cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for images that are similar to the provided image of test-meerkat, test-dog, test-cat\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path mediaType\")\n",
    "    .with_near_image(\n",
    "        # {\"image\": \"./test/test-meerkat.jpg\"}, # Use file path as the input for the query\n",
    "        # {\"image\": \"./test/test-dog.jpg\"}, # Use file path as the input for the query\n",
    "        {\"image\": \"./test/test-cat.jpg\"}, # Use file path as the input for the query\n",
    "    )\n",
    "    .with_limit(5)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "json_print(result)\n",
    "\n",
    "# Display the first image\n",
    "display_media(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio to Media search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio('./test/bird_audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for images that are similar to the provided image of test-meerkat, test-dog, test-cat\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path mediaType\")\n",
    "    .with_near_audio(\n",
    "        {\"audio\": \"./test/dog_audio.wav\"}, # Use file path as the input for the query\n",
    "        #{\"audio\": \"./test/bird_audio.wav\"}, # Use file path as the input for the query\n",
    "    )\n",
    "    .with_limit(5)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "json_print(result)\n",
    "\n",
    "# Display the first image\n",
    "display_media(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video to Media search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Video('test/test-meerkat.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for images that are similar to the provided image of test-meerkat, test-dog, test-cat\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Animals\", \"name path mediaType\")\n",
    "    .with_near_video(\n",
    "        # {\"video\": \"./test/test-dog.mp4\"}, # Use file path as the input for the query\n",
    "        # {\"video\": \"./test/test-cat.mp4\"}, # Use file path as the input for the query\n",
    "        {\"video\": \"./test/test-meerkat.mp4\"}, # Use file path as the input for the query\n",
    "    )\n",
    "    .with_limit(3)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "# Print results\n",
    "result = response[\"data\"][\"Get\"][\"Animals\"]\n",
    "json_print(result)\n",
    "\n",
    "# Display the first image\n",
    "display_media(result[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
